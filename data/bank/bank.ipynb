{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.distMix import distmix\n",
    "from utils.RSMOTENC import RSMOTENC\n",
    "from utils.SMOTEENC import SMOTEENC\n",
    "from utils.auxSamplingStudy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.data.bank.config import DATA, MODELS, REPORTS, idbin, idcat, idnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(DATA / 'bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= remove_outlier(df, 'age', 2.5)\n",
    "df= remove_outlier(df, 'campaign', 2.5)\n",
    "df= remove_outlier(df, 'emp.var.rate', 2.5)\n",
    "df= remove_outlier(df, 'cons.price.idx', 2.5)\n",
    "df= remove_outlier(df, 'cons.conf.idx', 2.5)\n",
    "df= remove_outlier(df, 'euribor3m', 2.5)\n",
    "df= remove_outlier(df, 'nr.employed', 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pdays_999 = df['pdays'] == 999\n",
    "df.loc[is_pdays_999, 'pdays_c'] = \"never contacted\"\n",
    "df.loc[~is_pdays_999, 'pdays_c'] = pd.qcut(df.loc[~is_pdays_999, 'pdays'], 4, labels=[\"very recently contacted\",\"recently contacted\", \"moderately recently contacted\", \"contacted long ago\"])\n",
    "df[['pdays_c', 'pdays']]\n",
    "\n",
    "df.drop('pdays', 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_previous_0 = df['previous'] == 0\n",
    "df.loc[is_previous_0, 'previous_c'] = \"never contacted\"\n",
    "df.loc[~is_previous_0, 'previous_c'] = pd.cut(df.previous,bins=[0, 1, 4, 7],labels=[\"contacted once\", \"rarely contacted\", \"frequently contacted\"])\n",
    "df[['previous_c', 'previous']]\n",
    "\n",
    "df.drop('previous', 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### In order to feed the data to any machine learning method, \n",
    "### it's convenient to change strings to numeric values. So, we are going to change 'no' to 0 and 'yes' to 1\n",
    "is_purchased = df['y'] == 'yes'\n",
    "df.loc[is_purchased, 'target'] = 1\n",
    "df.loc[~is_purchased, 'target'] = 0\n",
    "df[['target', 'y']]\n",
    "df.drop('y', 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006561</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.081826</td>\n",
       "      <td>0.054775</td>\n",
       "      <td>0.109962</td>\n",
       "      <td>0.092023</td>\n",
       "      <td>0.077782</td>\n",
       "      <td>-0.024210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>-0.006561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037328</td>\n",
       "      <td>-0.014408</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>-0.012044</td>\n",
       "      <td>-0.017155</td>\n",
       "      <td>-0.024651</td>\n",
       "      <td>0.423297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>0.006875</td>\n",
       "      <td>-0.037328</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101920</td>\n",
       "      <td>0.087973</td>\n",
       "      <td>-0.007239</td>\n",
       "      <td>0.081965</td>\n",
       "      <td>0.095540</td>\n",
       "      <td>-0.046072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp.var.rate</th>\n",
       "      <td>0.081826</td>\n",
       "      <td>-0.014408</td>\n",
       "      <td>0.101920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845136</td>\n",
       "      <td>0.328424</td>\n",
       "      <td>0.978759</td>\n",
       "      <td>0.954690</td>\n",
       "      <td>-0.257349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cons.price.idx</th>\n",
       "      <td>0.054775</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.087973</td>\n",
       "      <td>0.845136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190927</td>\n",
       "      <td>0.805977</td>\n",
       "      <td>0.735563</td>\n",
       "      <td>-0.185322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <td>0.109962</td>\n",
       "      <td>-0.012044</td>\n",
       "      <td>-0.007239</td>\n",
       "      <td>0.328424</td>\n",
       "      <td>0.190927</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397912</td>\n",
       "      <td>0.217505</td>\n",
       "      <td>0.027898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euribor3m</th>\n",
       "      <td>0.092023</td>\n",
       "      <td>-0.017155</td>\n",
       "      <td>0.081965</td>\n",
       "      <td>0.978759</td>\n",
       "      <td>0.805977</td>\n",
       "      <td>0.397912</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962600</td>\n",
       "      <td>-0.248442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nr.employed</th>\n",
       "      <td>0.077782</td>\n",
       "      <td>-0.024651</td>\n",
       "      <td>0.095540</td>\n",
       "      <td>0.954690</td>\n",
       "      <td>0.735563</td>\n",
       "      <td>0.217505</td>\n",
       "      <td>0.962600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.274426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>-0.024210</td>\n",
       "      <td>0.423297</td>\n",
       "      <td>-0.046072</td>\n",
       "      <td>-0.257349</td>\n",
       "      <td>-0.185322</td>\n",
       "      <td>0.027898</td>\n",
       "      <td>-0.248442</td>\n",
       "      <td>-0.274426</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age  duration  campaign  emp.var.rate  cons.price.idx  \\\n",
       "age             1.000000 -0.006561  0.006875      0.081826        0.054775   \n",
       "duration       -0.006561  1.000000 -0.037328     -0.014408        0.005740   \n",
       "campaign        0.006875 -0.037328  1.000000      0.101920        0.087973   \n",
       "emp.var.rate    0.081826 -0.014408  0.101920      1.000000        0.845136   \n",
       "cons.price.idx  0.054775  0.005740  0.087973      0.845136        1.000000   \n",
       "cons.conf.idx   0.109962 -0.012044 -0.007239      0.328424        0.190927   \n",
       "euribor3m       0.092023 -0.017155  0.081965      0.978759        0.805977   \n",
       "nr.employed     0.077782 -0.024651  0.095540      0.954690        0.735563   \n",
       "target         -0.024210  0.423297 -0.046072     -0.257349       -0.185322   \n",
       "\n",
       "                cons.conf.idx  euribor3m  nr.employed    target  \n",
       "age                  0.109962   0.092023     0.077782 -0.024210  \n",
       "duration            -0.012044  -0.017155    -0.024651  0.423297  \n",
       "campaign            -0.007239   0.081965     0.095540 -0.046072  \n",
       "emp.var.rate         0.328424   0.978759     0.954690 -0.257349  \n",
       "cons.price.idx       0.190927   0.805977     0.735563 -0.185322  \n",
       "cons.conf.idx        1.000000   0.397912     0.217505  0.027898  \n",
       "euribor3m            0.397912   1.000000     0.962600 -0.248442  \n",
       "nr.employed          0.217505   0.962600     1.000000 -0.274426  \n",
       "target               0.027898  -0.248442    -0.274426  1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num= df[['age','duration','campaign','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed','target']]\n",
    "corr_num = df_num.corr()\n",
    "corr_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp.var.rate and nr.employed are highly correlated with euribor3m. \n",
    "# That's why former two are removed to get rid of multi-collinearity.\n",
    "# Duration column is substantially correlated to target \n",
    "# and could be a good predictor of target outcome. \n",
    "# However, one can not know call duration before making the call. \n",
    "# That's why this column is removed so that the model can generalise on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('duration',1,inplace=True)\n",
    "df.drop('emp.var.rate',1,inplace=True)\n",
    "df.drop('nr.employed',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature= df.drop('target',1)\n",
    "df_target= df[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 32599, 1.0: 3519})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of minority instances is 3519 and majority instances is 32599"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data to be 5-fold cross-validated\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "#randomforest model - hyperparameter tuning using grid search\n",
    "param_grid = {\n",
    "'max_depth': [10], 'max_features': [5, 10],\n",
    "'min_samples_leaf': [3, 5], 'min_samples_split': [2, 4], 'n_estimators': [500]\n",
    "}# Create a base model\n",
    "param_grid = {'randomforestclassifier__' + key: param_grid[key] for key in param_grid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = MultiColumnLabelEncoder(columns = [ 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week',\n",
    "                                               'poutcome', 'pdays_c', 'previous_c']).fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'campaign', 'poutcome',\n",
       "       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'pdays_c', 'previous_c',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('job', 0.0), ('marital', 0.0), ('education', 0.0), ('default', 0.0), ('housing', 0.0), ('loan', 0.0), ('contact', 0.0), ('month', 0.0), ('day_of_week', 0.0), ('poutcome', 0.0), ('pdays_c', 0.0), ('previous_c', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "anovap_value = list()\n",
    "for cols in ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week',\n",
    "                                               'poutcome', 'pdays_c', 'previous_c']:\n",
    "    statistic, p = stats.f_oneway(encoded_df[cols], encoded_df['target'])\n",
    "    anovap_value.append(tuple([cols, p]))\n",
    "    \n",
    "print(anovap_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('job', 8.274959557723803e-85), ('marital', 1.0490021676190478e-27), ('education', 4.722556979141996e-30), ('default', 2.396736751936363e-56), ('housing', 0.019146278089660962), ('loan', 0.13725167724069698), ('contact', 3.456262374450821e-129), ('month', 0.0), ('day_of_week', 0.0019573310174748654), ('poutcome', 0.0), ('pdays_c', 0.0), ('previous_c', 7.705708237314738e-209)]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "chi2p_value = list()\n",
    "for cols in ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week',\n",
    "                                               'poutcome', 'pdays_c', 'previous_c']:\n",
    "    obs = pd.crosstab(encoded_df[cols], encoded_df['target'])\n",
    "    g, p, dof, expctd = chi2_contingency(obs)\n",
    "    chi2p_value.append(tuple([cols, p]))\n",
    "    \n",
    "print(chi2p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df= encoded_df.drop('target',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9446259482806357"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 2000 / encoded_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0.097431\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_target)/df_target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling: Added by me\n",
    "encoded_df, aux1, df_target, aux2 = train_test_split(encoded_df, df_target, test_size=0.95, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1805, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    153.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0.084765\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_target)/df_target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08333333333333333"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the raw data into train and test set. Split ratio = 75:25\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_df, df_target, test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(X_train.columns)\n",
    "X_train.index = pd.RangeIndex(len(X_train.index))\n",
    "y_train.index = pd.RangeIndex(len(y_train.index))\n",
    "X_test.index = pd.RangeIndex(len(X_test.index))\n",
    "y_test.index = pd.RangeIndex(len(y_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 17)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply standard scaler on the features , so that euclidean distance calculation in SMOTE is not biased\n",
    "\n",
    "columns = [0,10,12,13,14]\n",
    "name_columns = X_train.columns[columns]\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train[name_columns] = sc.fit_transform(X_train[name_columns])\n",
    "X_test[name_columns] = sc.transform(X_test[name_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, index=range(X_train.shape[0]),\n",
    "                          columns=col_list)\n",
    "X_test = pd.DataFrame(X_test, index=range(X_test.shape[0]),\n",
    "                          columns=col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1353, 17)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(DATA / \"bank_X_train.csv\", index = False)\n",
    "y_train.to_csv(DATA / \"bank_y_train.csv\", index = False)\n",
    "X_test.to_csv(DATA / \"bank_X_test.csv\", index = False)\n",
    "y_test.to_csv(DATA / \"bank_y_test.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python (SMOTE_ENC)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
